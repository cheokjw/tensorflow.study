{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np\n",
    "# Tensorflow keras API\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential([Dense(units = 1, input_shape = [1])]) \n",
    "- Calling sequential model\n",
    "- In tensorflow, we define layers using Sequential. In this case there is only one layer and one neuron \n",
    "- Dense means fully connected neurons for evey layers, units = 1 indicates that theres only one layer, input_shape indicates the input array shape\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "- This is the part where maths comes in\n",
    "- sgd stands for stochastic gradient scenarios (a type of optimizer)\n",
    "- Optimizer is used to minimize the loss by calculating the errors (or loss) on the previous guess can then generate another one\n",
    "\n",
    "model.fit(xs, ys, epochs=500)\n",
    "- We can read this as fit the Xs to the Ys, and try it 500 times\n",
    "- Then the process is being repeated for 500 times and each time the optimizer capture the loss value and optimizes the algorithm\n",
    "\n",
    "The term prediction is typically used when dealing with ML models.\n",
    "This term is used because we are dealing with a certain amount of uncertainties instead of predicting the future.\n",
    "The model will only return the answer that it thinks will probably be the answer (basically just guessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Dense(units = 1, input_shape = [1])]) \n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype = float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype = float)\n",
    "\n",
    "# Training model\n",
    "model.fit(xs, ys, epochs=500)\n",
    "\n",
    "# The answer is slightly off because the weight and bias is slightly off since we've only trained the model using 6 pairs of data\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program Output: Here is what I've learned : [array([[1.9966004]], dtype=float32), array([-0.98946005], dtype=float32)]\n",
    "\n",
    "This output indicates that the learned relationship between X and Y was Y = 1.9966004X - 0.98946005\n",
    "\n",
    "Neuron.get_weights() = obtaining the weight optimized by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing what the network learned\n",
    "l0 = Dense(units = 1, input_shape = [1])\n",
    "model = Sequential([l0])\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "model.fit(xs, ys, epochs = 500)\n",
    "\n",
    "print(model.predict([10.0]))\n",
    "print(f\"Here is what I've learned : {l0.get_weights()}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86024da591e1644f8f97b04427dfc49d410526f78c619fda20415da69f0ecd62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
