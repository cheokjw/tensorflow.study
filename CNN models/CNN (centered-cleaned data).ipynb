{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution\n",
    "- a filter of weights that are used to mulyiply a pixel with its neighbours to get a new value for the pixel\n",
    "- With this, we can potentially learn a set of filters that reduce the image to features. Combined with pooling, we can reduce the amount of information in the image while maintaining the features\n",
    "\n",
    "Eg:\n",
    "Image pixels             Filter\n",
    "[[0, 64, 128],          [[-1, 0, -2],\n",
    " [48, 192, 144],         [0.5, 4.5, -1.5],\n",
    " [142, 226, 168]]        [1.5, 2, -3]]\n",
    "\n",
    "Convolution formula = (-1 * 0) + (0 * 64) + (-2 * 128) +\n",
    "                      (0.5 * 48) + (4.5 * 192) + (-1.5 * 144) +\n",
    "                      (1.5 * 142) + (2 * 226) + (-3 * 168)\n",
    "- This equals to 577 which will be the new value for that pixel. Repeating this process across every pixel in the image will give us a filtered image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling\n",
    "- Pooling is the process of eliminating picels in the images while maintaining the semantics of the content within the image.\n",
    "\n",
    "1) Max pooling\n",
    "Image pixel (Total of 16 pixels)\n",
    "[[0, 64, 128, 128],\n",
    " [48, 192, 144, 144],\n",
    " [142, 226, 168, 0],\n",
    " [255, 0, 0, 64]\n",
    "]\n",
    "\n",
    "Then the pooling algorithm seperate the pixels into four equal parts, then the maximum value for each groups are selected\n",
    "[[0, 64],         [[128, 128],          [[142, 226]         [[168, 0],          \n",
    " [48, 192]]        [144, 144]]           [255, 0]]           [0, 64]]\n",
    "\n",
    "New pixel = [\n",
    "    [192, 144],\n",
    "    [255, 168]\n",
    "]\n",
    "\n",
    "- The filtered features is further enhanced and also, the image size has changed from 512 * 512 to 256 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing CNN with max pooling\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.nn import relu, softmax\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback class\n",
    "class myCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.95):\n",
    "            print(\"\\nAccuracy reached 95%!!! Stopping Training....\")\n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.4471 - accuracy: 0.8387\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 0.2971 - accuracy: 0.8897\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.2511 - accuracy: 0.9074\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.2183 - accuracy: 0.9182\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1913 - accuracy: 0.9275\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1699 - accuracy: 0.9368\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1482 - accuracy: 0.9444\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9502\n",
      "Accuracy reached 95%!!! Stopping Training....\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1311 - accuracy: 0.9502\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2647 - accuracy: 0.9102\n",
      "Model predictions : [1.0078699e-11 2.8727279e-10 1.3525836e-12 3.3344316e-10 9.1498650e-15\n",
      " 4.4131960e-09 9.4693567e-13 2.1928133e-06 2.7613831e-11 9.9999785e-01]\n",
      "Actual Answer : [1.0078699e-11 2.8727279e-10 1.3525836e-12 3.3344316e-10 9.1498650e-15\n",
      " 4.4131960e-09 9.4693567e-13 2.1928133e-06 2.7613831e-11 9.9999785e-01]\n"
     ]
    }
   ],
   "source": [
    "data = fashion_mnist\n",
    "callbacks = myCallback()\n",
    "\n",
    "(training_features, training_labels), (testing_features, testing_labels) = data.load_data()\n",
    "\n",
    "# Reshaping the data so it fits into the model\n",
    "training_features = training_features.reshape(60000, 28, 28, 1)\n",
    "training_features = training_features / 255.0\n",
    "testing_features = testing_features.reshape(10000, 28, 28, 1)\n",
    "testing_features = testing_features / 255.0\n",
    "\n",
    "\n",
    "# Creating Model\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation = 'relu', input_shape = (28, 28, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation = 'relu', input_shape = (28, 28, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = relu),\n",
    "    Dense(10, activation = softmax)\n",
    "\n",
    "])\n",
    "\n",
    "# Compiling Model\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Training Model\n",
    "model.fit(training_features, training_labels, epochs = 50, callbacks = [callbacks])\n",
    "\n",
    "model.evaluate(testing_features, testing_labels)\n",
    "\n",
    "classifications = model.predict(testing_features)\n",
    "print(f\"Model predictions : {classifications[0]}\")\n",
    "print(f\"Actual Answer : {classifications[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary() \n",
    "- returns an overall information about the model\n",
    "\n",
    "- Our first layer (input layer) will have 28 * 28. But because our filter is 3 * 3, a 1-pixel border around the image will be lost, reducing overall information to 26 * 26\n",
    "Example:-\n",
    "口  口  口   o   o   o\n",
    "口  x   口   o   o   o             口 = filter pixel\n",
    "口  口  口   o   o   o              x = first pixel to apply filter    \n",
    "o   o   o   o   o   o              o = remaining pixel\n",
    "o   o   o   o   o   o\n",
    "o   o   o   o   o   o\n",
    "- Thus, an image that is A * B pixels in shape when run through a N1 * N2 filter will become:\n",
    "(A - [N1 - 1]) * (B - [N2 - 2])\n",
    "\n",
    "Param #\n",
    "- parameter is similar to weight in neural network\n",
    "- becuase the filter is 3 * 3, there are 9 parameters to learn. given that we have 64 convolutions defined, we'll have 640 overall parameters.\n",
    "(Each convolution has 9 parameters plus a bias, for a total of 10) (64 * [9 + 1])\n",
    "\n",
    "- The MaxPooling layers don't learn anyhting, they just reduce the image, so there are no learned parameters there - hence 0 is being reported\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Inspecting model\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86024da591e1644f8f97b04427dfc49d410526f78c619fda20415da69f0ecd62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
