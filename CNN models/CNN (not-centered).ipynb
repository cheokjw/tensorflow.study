{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gLP0EvIACJNe"},"outputs":[],"source":["import urllib.request\n","import zipfile\n","import progressbar\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDHpc1ubCJNg","outputId":"00c783a4-1f5e-4a67-d5a6-2b7c196be323"},"outputs":[{"name":"stderr","output_type":"stream","text":["100% |########################################################################|\n"]}],"source":["# Downloads the zip of the training data and unzips it into a direcoty at horse-or-human/training\n","url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n","\n","\n","# Progress bar\n","pbar = None\n","\n","def show_progress(block_num, block_size, total_size):\n","    global pbar\n","    if pbar is None:\n","        pbar = progressbar.ProgressBar(maxval=total_size)\n","        pbar.start()\n","\n","    downloaded = block_num * block_size\n","    if downloaded < total_size:\n","        pbar.update(downloaded)\n","    else:\n","        pbar.finish()\n","        pbar = None\n","\n","\n","file_name = \"horse-or-human.zip\"\n","training_dir = 'horse-or-human/training/'\n","\n","urllib.request.urlretrieve(url, file_name, show_progress)\n","\n","zip_ref = zipfile.ZipFile(file_name, 'r')\n","zip_ref.extractall(training_dir)\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2NaD3UICJNi"},"outputs":[],"source":["# Adding Validation to the Horses or Humans Dataset\n","\n","validation_url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\"\n","\n","validation_file_name = \"validation-horse-or-human.zip\"\n","validation_dir = \"horse-or-human/validation/\"\n","urlretrieve(validation_url, validation_file_name, show_progress) # show_progress is for progression bar\n","\n","zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n","zip_ref.extractall(validation_dir)\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWLK5cgTCJNi","outputId":"7b28dba7-9168-49c5-8028-abeb7c7efefc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1027 images belonging to 2 classes.\n"]}],"source":["# Generating data\n","\n","train_datagen = ImageDataGenerator(rescale = 1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    training_dir,\n","    target_size = (300, 300),\n","    class_mode = 'binary'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZUy6NuzCJNj"},"outputs":[],"source":["# Generating Validation data\n","validation_datagen = ImageDataGenerator(rescale = 1/255)\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size = (300, 300),\n","    class_mode = 'binary'\n",")"]},{"cell_type":"markdown","metadata":{"id":"ysutrwHRCJNk"},"source":["Validation\n","- To add validation, you'll need a validation dataset that's separated from the training dataset.\n","- In some case you'll get a master dataset that you have to split yourself\n","\n","Difference between Training Data and Validation data and Testing Data\n","- Training data is the data that is used to teach the network how the data and labels fit together.\n","- Validation data is used to see how the network is doing with previously unseen data while you are training\n","- Test data is used after training to see how the network does with data it has never priviously seen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWW4lCrKCJNl"},"outputs":[],"source":["# CNN Architecture for Horses and Humans\n","\n","model = Sequential([\n","                    Conv2D(16, (3, 3), activation = 'relu', input_shape = (300, 300, 3)),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(32, (3, 3), activation = 'relu'),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(64, (3, 3), activation = 'relu'),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(64, (3, 3), activation = 'relu'),\n","                    MaxPooling2D(2, 2),\n","                    Conv2D(64, (3, 3), activation = 'relu'),\n","                    MaxPooling2D(2, 2),\n","                    Flatten(),\n","                    Dense(512, activation = 'relu'),\n","                    Dense(1, activation = 'sigmoid')\n","])\n","\n","# model.summary()\n","\n","# Compiling model\n","model.compile(loss = 'binary_crossentropy',\n","              optimizer = RMSprop(lr = 0.001),\n","              metrics = ['accuracy'])\n","\n","# Older generations uses model.fit_generator while the later can use either fit or that\n","model.fit(train_generator, epochs = 15, validation_data = validation_generator)\n","\n","model.evaluate(train_generator)"]},{"cell_type":"markdown","metadata":{},"source":["image.load_img loads the image from the path that Colab wrote it to and resize it to 300 x 300\n","image.img_to_array converts the image into a 2D-array\n","(But the model is expecting a 3D array)\n","Luckily, numpy has a function call np.expand_dims that handles  this and allows us to easily add a new dimension to the array"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np \n","from keras.preprocessing import image\n","import google.colab import files \n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","    path = f'/content/{fn}'\n","    img = image.load_img(path, target_size=(300, 300))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis = 0)\n","\n","    image_tensor = np.vstack([x])\n","    classes = model.predict(image_tensor)\n","    print(classes)\n","    print(classes[0])\n","    \n","    if classes[0] > 0.5:\n","        print(f\"{fn} is a human\")\n","    else:\n","        print(f\"{fn} is a horse\")"]}],"metadata":{"colab":{"name":"Copy of CNN (not-centered).ipynb","provenance":[{"file_id":"https://github.com/cheokjw/tensorflow.study/blob/main/CNN%20(not-centered).ipynb","timestamp":1642943242459}]},"interpreter":{"hash":"86024da591e1644f8f97b04427dfc49d410526f78c619fda20415da69f0ecd62"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
